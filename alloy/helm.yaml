apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
    name: alloy
    namespace: argocd
finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  destination:
      name: ''
      namespace: alloy
      server: 'https://kubernetes.default.svc'
  source:
      path: ''
      repoURL: 'https://grafana.github.io/helm-charts'
      targetRevision: '0.6.0'
      chart: alloy
      helm:
          values: |-
              nameOverride: null
              
              # -- Overrides the chart's computed fullname. Used to change the full prefix of
              # resource names.
              fullnameOverride: null
              
              ## Global properties for image pulling override the values defined under `image.registry` and `configReloader.image.registry`.
              ## If you want to override only one image registry, use the specific fields but if you want to override them all, use `global.image.registry`
              global:
                image:
                  # -- Global image registry to use if it needs to be overriden for some specific use cases (e.g local registries, custom images, ...)
                  registry: ""
              
                  # -- Optional set of global image pull secrets.
                  pullSecrets: []
              
                # -- Security context to apply to the Grafana Alloy pod.
                podSecurityContext: {}
              
              crds:
                # -- Whether to install CRDs for monitoring.
                create: true
              
              ## Various Alloy settings. For backwards compatibility with the grafana-agent
              ## chart, this field may also be called "agent". Naming this field "agent" is
              ## deprecated and will be removed in a future release.
              alloy:
                configMap:
                  content: |-
                                # -- Overrides the chart's name. Used to change the infix in the resource names.
              nameOverride: null
              
              # -- Overrides the chart's computed fullname. Used to change the full prefix of
              # resource names.
              fullnameOverride: null
              
              ## Global properties for image pulling override the values defined under `image.registry` and `configReloader.image.registry`.
              ## If you want to override only one image registry, use the specific fields but if you want to override them all, use `global.image.registry`
              global:
                image:
                  # -- Global image registry to use if it needs to be overriden for some specific use cases (e.g local registries, custom images, ...)
                  registry: ""
              
                  # -- Optional set of global image pull secrets.
                  pullSecrets: []
              
                # -- Security context to apply to the Grafana Alloy pod.
                podSecurityContext: {}
              
              crds:
                # -- Whether to install CRDs for monitoring.
                create: true
              
              ## Various Alloy settings. For backwards compatibility with the grafana-agent
              ## chart, this field may also be called "agent". Naming this field "agent" is
              ## deprecated and will be removed in a future release.
              alloy:
                configMap:
                  content: |-
              # -- Overrides the chart's name. Used to change the infix in the resource names.
              nameOverride: null
              
              # -- Overrides the chart's computed fullname. Used to change the full prefix of
              # resource names.
              fullnameOverride: null
              
              ## Global properties for image pulling override the values defined under `image.registry` and `configReloader.image.registry`.
              ## If you want to override only one image registry, use the specific fields but if you want to override them all, use `global.image.registry`
              global:
                image:
                  # -- Global image registry to use if it needs to be overriden for some specific use cases (e.g local registries, custom images, ...)
                  registry: ""
              
                  # -- Optional set of global image pull secrets.
                  pullSecrets: []
              
                # -- Security context to apply to the Grafana Alloy pod.
                podSecurityContext: {}
              
              crds:
                # -- Whether to install CRDs for monitoring.
                create: true
              
              ## Various Alloy settings. For backwards compatibility with the grafana-agent
              ## chart, this field may also be called "agent". Naming this field "agent" is
              ## deprecated and will be removed in a future release.
              alloy:
                configMap:
                  content: |-
                    logging {
                      level = "info"
                      format = "logfmt"
                      write_to = [loki.write.default.receiver]
                    }
                    loki.write "default" {
                      endpoint {
                        url = "http://loki.loki.svc.cluster.local:3100/loki/api/v1/push"
                      }
                    }
                    // local.file_match discovers files on the local filesystem using glob patterns and the doublestar library. It returns an array of file paths.
                    local.file_match "node_logs" {
                      path_targets = [{
                          // Monitor syslog to scrape node-logs
                          __path__  = "/var/log/syslog",
                          job       = "node/syslog",
                          node_name = env("HOSTNAME"),
                          cluster   = k3s,
                      }]
                    }
              
                    // loki.source.file reads log entries from files and forwards them to other loki.* components.
                    // You can specify multiple loki.source.file components by giving them different labels.
                    loki.source.file "node_logs" {
                      targets    = local.file_match.node_logs.targets
                      forward_to = [loki.write.default.receiver]
                    }
                    // discovery.kubernetes allows you to find scrape targets from Kubernetes resources.
                    // It watches cluster state and ensures targets are continually synced with what is currently running in your cluster.
                    discovery.kubernetes "pod" {
                      role = "pod"
                    }
              
                    // discovery.relabel rewrites the label set of the input targets by applying one or more relabeling rules.
                    // If no rules are defined, then the input targets are exported as-is.
                    discovery.relabel "pod_logs" {
                      targets = discovery.kubernetes.pod.targets
              
                      // Label creation - "namespace" field from "__meta_kubernetes_namespace"
                      rule {
                        source_labels = ["__meta_kubernetes_namespace"]
                        action = "replace"
                        target_label = "namespace"
                      }
              
                      // Label creation - "pod" field from "__meta_kubernetes_pod_name"
                      rule {
                        source_labels = ["__meta_kubernetes_pod_name"]
                        action = "replace"
                        target_label = "pod"
                      }
              
                      // Label creation - "container" field from "__meta_kubernetes_pod_container_name"
                      rule {
                        source_labels = ["__meta_kubernetes_pod_container_name"]
                        action = "replace"
                        target_label = "container"
                      }
              
                      // Label creation -  "app" field from "__meta_kubernetes_pod_label_app_kubernetes_io_name"
                      rule {
                        source_labels = ["__meta_kubernetes_pod_label_app_kubernetes_io_name"]
                        action = "replace"
                        target_label = "app"
                      }
              
                      // Label creation -  "job" field from "__meta_kubernetes_namespace" and "__meta_kubernetes_pod_container_name"
                      // Concatenate values __meta_kubernetes_namespace/__meta_kubernetes_pod_container_name
                      rule {
                        source_labels = ["__meta_kubernetes_namespace", "__meta_kubernetes_pod_container_name"]
                        action = "replace"
                        target_label = "job"
                        separator = "/"
                        replacement = "$1"
                      }
              
                      // Label creation - "container" field from "__meta_kubernetes_pod_uid" and "__meta_kubernetes_pod_container_name"
                      // Concatenate values __meta_kubernetes_pod_uid/__meta_kubernetes_pod_container_name.log
                      rule {
                        source_labels = ["__meta_kubernetes_pod_uid", "__meta_kubernetes_pod_container_name"]
                        action = "replace"
                        target_label = "__path__"
                        separator = "/"
                        replacement = "/var/log/pods/*$1/*.log"
                      }
              
                      // Label creation -  "container_runtime" field from "__meta_kubernetes_pod_container_id"
                      rule {
                        source_labels = ["__meta_kubernetes_pod_container_id"]
                        action = "replace"
                        target_label = "container_runtime"
                        regex = "^(\\S+):\\/\\/.+$"
                        replacement = "$1"
                      }
                    }
              
                    // loki.source.kubernetes tails logs from Kubernetes containers using the Kubernetes API.
                    loki.source.kubernetes "pod_logs" {
                      targets    = discovery.relabel.pod_logs.output
                      forward_to = [loki.process.pod_logs.receiver]
                    }
              
                    // loki.process receives log entries from other Loki components, applies one or more processing stages,
                    // and forwards the results to the list of receivers in the component’s arguments.
                    loki.process "pod_logs" {
                      stage.static_labels {
                          values = {
                            cluster = "k3s",
                          }
                      }
              
                      forward_to = [loki.write.default.receiver]
                    }
                    // loki.source.kubernetes_events tails events from the Kubernetes API and converts them
                    // into log lines to forward to other Loki components.
                    loki.source.kubernetes_events "cluster_events" {
                      job_name   = "integrations/kubernetes/eventhandler"
                      log_format = "logfmt"
                      forward_to = [
                        loki.process.cluster_events.receiver,
                      ]
                    }
              
                    // loki.process receives log entries from other loki components, applies one or more processing stages,
                    // and forwards the results to the list of receivers in the component’s arguments.
                    loki.process "cluster_events" {
                      forward_to = [loki.write.default.receiver]
              
                      stage.static_labels {
                        values = {
                          cluster = "k3s",
                        }
                      }
              
                      stage.labels {
                        values = {
                          kubernetes_cluster_events = "job",
                        }
                      }
                    }
                    prometheus.remote_write "default" {
                      endpoint {
                        url = "http://mimir-nginx.mimir.svc.cluster.local"
                      }
                    }
                    prometheus.scrape "example" {
                      // Collect metrics from the default listen address.
                      targets = [{
                        __address__ = "127.0.0.1:12345",
                      }]
              
                      forward_to = [prometheus.remote_write.default.receiver]
                    }
                    discovery.kubernetes "pod_metrics" {
                      role = "pod"
                    }
                    prometheus.scrape "<SCRAPE_LABEL>" {
                      targets    = discovery.kubernetes.pod_metrics.targets
                      forward_to = [prometheus.remote_write.default.receiver]
                    }
                  # -- Create a new ConfigMap for the config file.
                  create: true
                  # -- Content to assign to the new ConfigMap.  This is passed into `tpl` allowing for templating from values.
                  content: ''
              
                  # -- Name of existing ConfigMap to use. Used when create is false.
                  name: null
                  # -- Key in ConfigMap to get config from.
                  key: null
              
                clustering:
                  # -- Deploy Alloy in a cluster to allow for load distribution.
                  enabled: false
              
                  # -- Name for the port used for clustering, useful if running inside an Istio Mesh
                  portName: http
              
                # -- Minimum stability level of components and behavior to enable. Must be
                # one of "experimental", "public-preview", or "generally-available".
                stabilityLevel: "generally-available"
              
                # -- Path to where Grafana Alloy stores data (for example, the Write-Ahead Log).
                # By default, data is lost between reboots.
                storagePath: /tmp/alloy
              
                # -- Address to listen for traffic on. 0.0.0.0 exposes the UI to other
                # containers.
                listenAddr: 0.0.0.0
              
                # -- Port to listen for traffic on.
                listenPort: 12345
              
                # -- Scheme is needed for readiness probes. If enabling tls in your configs, set to "HTTPS"
                listenScheme: HTTP
              
                # --  Base path where the UI is exposed.
                uiPathPrefix: /
              
                # -- Enables sending Grafana Labs anonymous usage stats to help improve Grafana
                # Alloy.
                enableReporting: true
              
                # -- Extra environment variables to pass to the Alloy container.
                extraEnv: []
              
                # -- Maps all the keys on a ConfigMap or Secret as environment variables. https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.24/#envfromsource-v1-core
                envFrom: []
              
                # -- Extra args to pass to `alloy run`: https://grafana.com/docs/alloy/latest/reference/cli/run/
                extraArgs: []
              
                # -- Extra ports to expose on the Alloy container.
                extraPorts: []
                # - name: "faro"
                #   port: 12347
                #   targetPort: 12347
                #   protocol: "TCP"
              
                mounts:
                  # -- Mount /var/log from the host into the container for log collection.
                  varlog: false
                  # -- Mount /var/lib/docker/containers from the host into the container for log
                  # collection.
                  dockercontainers: false
              
                  # -- Extra volume mounts to add into the Grafana Alloy container. Does not
                  # affect the watch container.
                  extra: []
              
                # -- Security context to apply to the Grafana Alloy container.
                securityContext: {}
              
                # -- Resource requests and limits to apply to the Grafana Alloy container.
                resources: {}
              
              image:
                # -- Grafana Alloy image registry (defaults to docker.io)
                registry: "docker.io"
                # -- Grafana Alloy image repository.
                repository: grafana/alloy
                # -- (string) Grafana Alloy image tag. When empty, the Chart's appVersion is
                # used.
                tag: null
                # -- Grafana Alloy image's SHA256 digest (either in format "sha256:XYZ" or "XYZ"). When set, will override `image.tag`.
                digest: null
                # -- Grafana Alloy image pull policy.
                pullPolicy: IfNotPresent
                # -- Optional set of image pull secrets.
                pullSecrets: []
              
              rbac:
                # -- Whether to create RBAC resources for Alloy.
                create: true
              
              serviceAccount:
                # -- Whether to create a service account for the Grafana Alloy deployment.
                create: true
                # -- Additional labels to add to the created service account.
                additionalLabels: {}
                # -- Annotations to add to the created service account.
                annotations: {}
                # -- The name of the existing service account to use when
                # serviceAccount.create is false.
                name: null
              
              # Options for the extra controller used for config reloading.
              configReloader:
                # -- Enables automatically reloading when the Alloy config changes.
                enabled: true
                image:
                  # -- Config reloader image registry (defaults to docker.io)
                  registry: "ghcr.io"
                  # -- Repository to get config reloader image from.
                  repository: jimmidyson/configmap-reload
                  # -- Tag of image to use for config reloading.
                  tag: v0.12.0
                  # -- SHA256 digest of image to use for config reloading (either in format "sha256:XYZ" or "XYZ"). When set, will override `configReloader.image.tag`
                  digest: ""
                # -- Override the args passed to the container.
                customArgs: []
                # -- Resource requests and limits to apply to the config reloader container.
                resources:
                  requests:
                    cpu: "1m"
                    memory: "5Mi"
                # -- Security context to apply to the Grafana configReloader container.
                securityContext: {}
              
              controller:
                # -- Type of controller to use for deploying Grafana Alloy in the cluster.
                # Must be one of 'daemonset', 'deployment', or 'statefulset'.
                type: 'daemonset'
              
                # -- Number of pods to deploy. Ignored when controller.type is 'daemonset'.
                replicas: 1
              
                # -- Annotations to add to controller.
                extraAnnotations: {}
              
                # -- Whether to deploy pods in parallel. Only used when controller.type is
                # 'statefulset'.
                parallelRollout: true
              
                # -- Configures Pods to use the host network. When set to true, the ports that will be used must be specified.
                hostNetwork: false
              
                # -- Configures Pods to use the host PID namespace.
                hostPID: false
              
                # -- Configures the DNS policy for the pod. https://kubernetes.io/docs/concepts/services-networking/dns-pod-service/#pod-s-dns-policy
                dnsPolicy: ClusterFirst
              
                # -- Update strategy for updating deployed Pods.
                updateStrategy: {}
              
                # -- nodeSelector to apply to Grafana Alloy pods.
                nodeSelector: {}
              
                # -- Tolerations to apply to Grafana Alloy pods.
                tolerations: []
              
                # -- Topology Spread Constraints to apply to Grafana Alloy pods.
                topologySpreadConstraints: []
              
                # -- priorityClassName to apply to Grafana Alloy pods.
                priorityClassName: ''
              
                # -- Extra pod annotations to add.
                podAnnotations: {}
              
                # -- Extra pod labels to add.
                podLabels: {}
              
                # -- Whether to enable automatic deletion of stale PVCs due to a scale down operation, when controller.type is 'statefulset'.
                enableStatefulSetAutoDeletePVC: false
              
                autoscaling:
                  # -- Creates a HorizontalPodAutoscaler for controller type deployment.
                  enabled: false
                  # -- The lower limit for the number of replicas to which the autoscaler can scale down.
                  minReplicas: 1
                  # -- The upper limit for the number of replicas to which the autoscaler can scale up.
                  maxReplicas: 5
                  # -- Average CPU utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetCPUUtilizationPercentage` to 0 will disable CPU scaling.
                  targetCPUUtilizationPercentage: 0
                  # -- Average Memory utilization across all relevant pods, a percentage of the requested value of the resource for the pods. Setting `targetMemoryUtilizationPercentage` to 0 will disable Memory scaling.
                  targetMemoryUtilizationPercentage: 80
              
                  scaleDown:
                    # -- List of policies to determine the scale-down behavior.
                    policies: []
                      # - type: Pods
                      #   value: 4
                      #   periodSeconds: 60
                    # -- Determines which of the provided scaling-down policies to apply if multiple are specified.
                    selectPolicy: Max
                    # -- The duration that the autoscaling mechanism should look back on to make decisions about scaling down.
                    stabilizationWindowSeconds: 300
              
                  scaleUp:
                    # -- List of policies to determine the scale-up behavior.
                    policies: []
                      # - type: Pods
                      #   value: 4
                      #   periodSeconds: 60
                    # -- Determines which of the provided scaling-up policies to apply if multiple are specified.
                    selectPolicy: Max
                    # -- The duration that the autoscaling mechanism should look back on to make decisions about scaling up.
                    stabilizationWindowSeconds: 0
              
                # -- Affinity configuration for pods.
                affinity: {}
              
                volumes:
                  # -- Extra volumes to add to the Grafana Alloy pod.
                  extra: []
              
                # -- volumeClaimTemplates to add when controller.type is 'statefulset'.
                volumeClaimTemplates: []
              
                ## -- Additional init containers to run.
                ## ref: https://kubernetes.io/docs/concepts/workloads/pods/init-containers/
                ##
                initContainers: []
              
                # -- Additional containers to run alongside the Alloy container and initContainers.
                extraContainers: []
              
              service:
                # -- Creates a Service for the controller's pods.
                enabled: true
                # -- Service type
                type: ClusterIP
                # -- NodePort port. Only takes effect when `service.type: NodePort`
                nodePort: 31128
                # -- Cluster IP, can be set to None, empty "" or an IP address
                clusterIP: ''
                # -- Value for internal traffic policy. 'Cluster' or 'Local'
                internalTrafficPolicy: Cluster
                annotations: {}
                  # cloud.google.com/load-balancer-type: Internal
              
              serviceMonitor:
                enabled: false
                # -- Additional labels for the service monitor.
                additionalLabels: {}
                # -- Scrape interval. If not set, the Prometheus default scrape interval is used.
                interval: ""
                # -- MetricRelabelConfigs to apply to samples after scraping, but before ingestion.
                # ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
                metricRelabelings: []
                # - action: keep
                #   regex: 'kube_(daemonset|deployment|pod|namespace|node|statefulset).+'
                #   sourceLabels: [__name__]
              
                # -- Customize tls parameters for the service monitor
                tlsConfig: {}
              
                # -- RelabelConfigs to apply to samples before scraping
                # ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/api.md#relabelconfig
                relabelings: []
                # - sourceLabels: [__meta_kubernetes_pod_node_name]
                #   separator: ;
                #   regex: ^(.*)$
                #   targetLabel: nodename
                #   replacement: $1
                #   action: replace
              ingress:
                # -- Enables ingress for Alloy (Faro port)
                enabled: false
                # For Kubernetes >= 1.18 you should specify the ingress-controller via the field ingressClassName
                # See https://kubernetes.io/blog/2020/04/02/improvements-to-the-ingress-api-in-kubernetes-1.18/#specifying-the-class-of-an-ingress
                # ingressClassName: nginx
                # Values can be templated
                annotations:
                  {}
                  # kubernetes.io/ingress.class: nginx
                  # kubernetes.io/tls-acme: "true"
                labels: {}
                path: /
                faroPort: 12347
              
                # pathType is only for k8s >= 1.1=
                pathType: Prefix
              
                # hosts:
                #   - chart-example.local
                ## Extra paths to prepend to every host configuration. This is useful when working with annotation based services.
                extraPaths: []
                # - path: /*
                #   backend:
                #     serviceName: ssl-redirect
                #     servicePort: use-annotation
                ## Or for k8s > 1.19
                # - path: /*
                #   pathType: Prefix
                #   backend:
                #     service:
                #       name: ssl-redirect
                #       port:
                #         name: use-annotation
              
                tls: []
                #  - secretName: chart-example-tls
                #    hosts:
                #      - chart-example.local
  sources: []
  project: default
  syncPolicy:
      automated:
          prune: true
          selfHeal: true
      retry:
          limit: 2
          backoff:
              duration: 5s
              maxDuration: 3m0s
              factor: 2
      syncOptions:
          - CreateNamespace=true
